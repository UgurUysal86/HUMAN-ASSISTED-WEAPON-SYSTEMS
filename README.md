# Research Practicum 2018 – Research Plan of Group 4

#### Group Name: **Terminators**
#### Group participants names: **Cabrera, Roberto & Uysal, Ugur**
#### Project Title: **HUMAN-ASSISTED WEAPON SYSTEMS**

#### **Project Presentation Video:**
[![HUMAN-ASSISTED WEAPON SYSTEMS](https://github.com/jedioutcast55/project_template/blob/master/Images/ArmA%203%20Ingame%20Screenshot%20Drones.JPG)](https://raw.githubusercontent.com/jedioutcast55/project_template/ca9b90bb2441154212237af3f4c7026827d156e8/Project%20Review%20and%20Feedback/IDS6916_Group4_MidSemester_ProjectPresentation.mp4)
**Download instructions**: Please click on this image to download the Project Presentation Video. Note: Please use a browser other than Firefox to be able to download this video from GitHub. [The **Project Presentation Slides** can be downloaded here.](https://github.com/jedioutcast55/project_template/raw/bb90194dd070cc2e5d15da00ee9aa7aa9380520d/Project%20Review%20and%20Feedback/IDS6916%20Group4%20Project%20Review%20and%20Feedback_UCF.pptx)

## 1. Topic / Purpose Statement

This study addresses the validity of human-autonomy teaming on the battlefield in the near future. The purpose of this exploratory research is to create a framework using the military tactical shooter video game ArmA 3 as a modeling and simulation platform to conduct experimentation on Human-assisted Weapon systems. The first phase of the study will be a qualitative exploration of the human-autonomous teaming to gather data and knowledge to ascertain the near future prospects. The data will help in the design of more realistic scenarios that will allow us to conduct quantitative experiments using ArmA 3. The data is collected from the literature review and interviews with subject matter experts (SME). From the initial exploration, the qualitative findings will be used to develop a quantitative experimentation on a human subject interacting with semi-autonomous entities. In the quantitative phase, reliability data will be collected from experiments conducted using ArmA 3.

## 2. Introduction

"Twenty years from now, unless we can replace a considerable number of people with robots, it’ll be hard to maintain the current level of war capability,” said Akihisa Nagashima, a former parliamentary vice defence minister and conservative independent lawmaker. “Japan’s (security) situation won’t be more peaceful, so I think this is really serious" (Reuters, 2018). 

Armed forces use technology to gain superiority on the battlefield. Recent breakthroughs in the field of Artificial Intelligence and Unmanned Systems provide new uses for military operations. The Control of Unmanned Systems can be done at different levels of autonomy. The focus of this research is the Human-autonomy teaming approach. In contrast to Manned-unmanned teaming, where the unmanned systems are not operated by human operators. With our research we would like to investigate the possibilities to operate unmanned systems autonomously, to increase the effectiveness of military forces on the near future battlefield.

On July 10, 2013, an unmanned X45B drone made an autonomous landing on an aircraft carrier for the first time:
[![X-47B Completes First Carrier-based Arrested Landing](https://github.com/jedioutcast55/project_template/blob/master/Images/X-47B%20Completes%20First%20Carrier-based%20Arrested%20Landing.JPG)](https://www.youtube.com/watch?v=Rc2k6G8LuqY)

The simulation of the supervised-autonomous landing of the UCAV Sentinel in ArmA 3 looks realistic:
[![UCAV Sentinel Completes Carrier-based Arrested Landing in ArmA 3](https://github.com/jedioutcast55/project_template/blob/master/Images/ArmA%203%20Ingame%20Screenshot%20UCAV%20Sentinel%20Completes%20Carrier-based%20Arrested%20Landing.JPG)](https://www.youtube.com/watch?v=3vW2kUt7PLQ&feature=youtu.be)

The military use of autonomous drones in varying degrees of intensity seems to be possible in the foreseeable future. Our basic principle is that the human military leader remains at any time the decision-making authority to carry out military operations. With our research, we would like to investigate the possibilities and limits of human-supervised autonomous systems on the future battlefield. The focus is on the reliability of the Human-supervised autonomous system in a virtual military scenario.

This problem is interesting, as the full military potential of Human-autonomy teaming can currently only be estimated, as the technology required is just being developed. Therefore we rely as part of our research project on the virtual simulation environment ArmA 3, in which a human operator can give orders to several autonomous systems at the same time. The following video gives an impression of how the AI control in ArmA 3 can be managed: 
[![ARMA 3 - Advanced AI Command Tactics](https://github.com/jedioutcast55/project_template/blob/master/Images/ARMA%203%20-%20Advanced%20AI%20Command%20Tactics.JPG)](https://www.youtube.com/watch?v=QphmHgvYlJw&t=1290s)

With the knowledge we gain from the simulation experiments we try the answer our research questions. Furthermore, we refer to approaches in this field by other researchers and delineate our approach.

This project makes the following contributions:
* Presentation of the current status of research on Human-autonomy teaming in the military field of application.
* Exploration of the possibilities and limits of Human-autonomy teaming in various military scenarios through simulation experiments.

## 3. Related Work / literature review

When searching for literature on the topic of Human-assisted Weapon Systems, we mostly found terms such as Manned-unmanned teaming and Human-autonomy teaming. It is striking that the term Human-autonomy teaming is used more frequently in the latest publications. This is related to advances in the field of autonomous systems in recent years and the resulting potential in the military sector. Manned-unmanned teaming is the collaboration between a system of human inmates and a human remote controlled system without human occupants. In Human-autonomy teaming, the unmanned system is autonomously controlled by an agent or AI and is not remotely controlled by a human operator. According to Scharre (2018) "A machine can perform a task in a semi-autonomous, supervised autonomous, or fully autonomous manner" (p.28). "In semiautonomous systems, the machine performs a task and then waits for a human user to take an action before continuing." (Scharre, 2018, p. 29). "Once put into operation, the machine can sense, decide, and act on its own, but a human user can observe the machine's behavior and intervene to stop it, if desired" (Scharre, 2018, p. 29). "Fully autonomous systems sense, decide, and act entirely without human intervention. Once the human activates the machine, it conducts the task without communication back to the human user." (Scharre, 2018, p. 30).

Chen (2018) summarizes recent articles that highlight the growing relevance of using Human-autonomy teaming in the military field. Chen (2018) explains that the Defense Science Board (2016) states that "Intelligent autonomous systems have become increasingly important in military missions" (p.255). Chen (2018) claims that "As these systems become more intelligent and sophisticated - and autonomous - human-autonomy teaming has become a key issue to address" (p.255). According to Chen & Barnes (2014) rules and procedures are designed so that the following is ensured: "efficient human supervision of multiple robots, appropriate human trust in the automated systems, maintenance of human operator’s situation awareness, individual differences in human–agent (H-A) interaction, and retention of human decision authority" (p.13).

Many research articles focus on ethical and legal aspects of the military use of autonomous systems. 
For example, de Boisboissel (2017) states that "all machines, including autonomous lethal robotic systems, must remain under the tactical control of the military leader" (p.738). Dyndal& Redse-Johansen (2017) states that "Some see the new opportunities and potential benefits of using autonomous drones, others consider the development and use of such technology as inherently immoral". Furthermore Dyndal & Redse-Johansen (2017) states that "The limiting factor is not the technology but rather the political will to develop or admit to having such politically sensitive technology, which would allow lethal machines to operate without being under the direct control of humans." For the project group members it is important to emphasize that, in this context, every final decision over using lethal force has to be made by the human user, as this topic is also negatively afflicted and can encounter rejection. By coining the term of the technical singularity, Vinge (1993) warned that immediately after the development of Artificial Super Intelligence, the end of humanity would be imminent. Also, Stephen Hawking warned that AI could bring the end to humanity (Hawking 2014). This scenario has also been used in science fiction films, e.g., The Terminator (1984). 

It is imperative not only to understand the ethical implications of using autonomous systems in war. There is also a need to understand how a human in a human-autonomy team interacts in the war. Squire P. N. & Parasuraman R (2010) conducted an experiment in which a human controlled a determined number of robots in a capturing the flag game. They collected the data on supervisor (human) task switching performance (complex tasks vs. repetitive tasks) and teams of four and eight robots performance (winning percentage). Squire and Parasuraman wanted to understand how the cognitive load and the Level of Automation (LOA) affected each robot team. Squire and Parasuraman used the results to establish ideas on how to better design an interface that would reduce the cognitive load and become more efficient in conducting tasks. This experiment is the foundation for the understanding of the human-autonomy teaming interaction.

## 4. Research Method

The subject of interest is relatively new to our group. With the desire to explore the topic, the group started to read articles, books, web-pages, etc. After the initial research the group was able focus the research study into the subject of human-autonomy teaming. 

The group was interested to find out about the interaction between the human supervisor and autonomous systems and what are some of the difficulties this new paradigm may have. To refine this concept the group started to define a model where the human has supervisory functions on the autonomous systems during simulated operations. The group’s intent is to demonstrate the new paradigm using simulation. The intent is to use simulation to collect data, then analyze the data and produce a conclusion based on the results.
  
We want to use a **Mixed Method Approach** as defined by Creswell & Creswell (2017) to answer research questions related to this projects contributions. First, we want to answer the qualitative research questions by literature review and interviews with experts in the field of human-autonomy teaming. In the second step we want to collect, analyze, and interpret quantitative data through simulation experiments using ArmA 3. We want to answer the quantitative research question by simulation experiments that are viable for human-autonomy teaming experimentation.

### 4.1 Qualitative Research Questions

#### Central question: What are the benefits of using human-supervised autonomous systems in a military environment?
The military is looking into increasing their capabilities by introducing unmanned vehicles (UVs) and robotic systems (Squire & Parasuraman, 2010) (de Visser & Parasuraman, 2011) (Chen & Barnes 2014).  The factors driving the introduction of UVs are: to increase force lethality, perform survivor evacuation, and reduce human exposure to combat operations (Chen & Barnes 2014).  Other factors are the reduction in personnel, reduction in labor cost, improve human safety and cost-saving ways to perform tasks without the human limitations and expense (Squire & Parasuraman, 2010) (Endsley, 2017).  The literature provides some evidence where the use of human-supervised autonomous systems has been beneficial.
   
#### Subquestion 1: What is the current status of research on Human-autonomy teaming in the military?
Current research being performed on the subject of dismounted infantry working with small robots, intelligent analysis, human working with intelligent agents managing teams of unmanned vehicles, and vehicles with ground penetrating radars (Chen, 2018).  Most of the research perform is on the efficacy of using these systems.  Some research performed in human-automation teaming is looking at the behavior and the synchronization between teams (Demir, McNeese, and Cooke, 2018).  There are a number of researches being conducted in the field of human-autonomy systems.  Some of the research concentrates on the cognitive load of the human agent and how to decrease it.

#### Subquestion 2: How could autonomous systems be integrated into the armed forces, ensuring that legal aspects are adhered to?
The suggestion for autonomous systems to ensure they adhered to legal implication is to rest the authority on a human supervisor (Chen & Barnes 2014). Humans still understand patterns behavior, human intentions, macro implications and ethical responsibilities much better than artificial systems (Chen & Barnes 2014). For this reason, the system autonomous agent shall always remain subordinate to their human counterparts (Chen & Barnes 2014). The human will only allow the agent to act autonomously only under specified conditions (Chen & Barnes 2014). John H. Northrop and Associate conducted a study which suggests developing a matrix defining the level of automation (Chesebrough & Dooley, 2018).  This matrix should provide the need and level of autonomous tactical needed to accomplish the mission within the constraints of mission parameters (Chesebrough & Dooley, 2018). The literature has provided a number of solutions to integrate rules of engagement, ethical and legal tenets.
   
### 4.2 Quantitative Research Question: Does the use of autonomous systems have positive effects on military capabilities?

#### Hypothesis 1: Unmanned Systems can be operated autonomously with the same reliability as human-operated once in a virtual military scenario. 

#### Hypothesis 2: By using autonomous systems, military missions can be conducted with less human personnel.

#### Hypothesis 3: The use of autonomous systems could extend the range of military operations.

## 5. Preliminary framework / setup of the experimental Study Method Plan
To answer our projects quantitative research questions we set up an experimental Design to "manipulates one or more variables in order to evaluate how this manipulation impacts an outcome or outcomes of interest" (Creswell & Creswell, 2018, p. 147) with the following components:

### 5.1 Participants
Our group will create scenarios to compare human actions against autonomous agents to determine the reliability of the autonomous agents. One or both members of our research group will act as human users in the simulation. At this time no further human participants are needed. If further persons are needed, then gamers which have been exposed to the simulation framework or military personnel which has experience with dealing with unmanned systems would be best suited for this.

### 5.2 Variables
#### 5.2.1 Independent variables:
* Level of autonomy  {semi-autonomous, supervised autonomous, fully autonomous},
* Amount of targets {1..n} 
* Amount of UCAV (Unmanned Combat Aerial Vehicle ) {1..n}
* Available Munitions {GBU, AGM} 
* Amount of unbound vehicles {1..n}
* Complexity of Scenario {low, middle, high}

#### 5.2.2 Dependent variables (Responses):
* Amount of destroyed targets {1..n} 
* Amount of UCAV at the end of the mission {1..n} 
* Elapsed Time since command received (sec) {1..n} 
* Amount of used Ammunition {1..n} 
* Only hostile targets engaged {True = 1, False = 0}
* Operator was able to  supervise all used autonomous systems {True = 1, False = 0}
* Operator perception of  cognitive workload  {1..10}

### 5.3 Instrumentation and Materials
Since the full potential of autonomous systems can only be estimated today due to technologies that are not yet fully developed, we want to use a simulation environment in which these technologies are already available. Therefore we use virtual simulation instead of robotics for our experiments. The military tactical shooter video game [ArmA 3](https://arma3.com/) Version 1.84.144923 including the Downloadable Content's (DLC) ["Apex"](https://arma3.com/apex), ["Jets"](https://arma3.com/dlc/jets), ["Tanks"](https://arma3.com/dlc/tanks), and ["Zeus"](https://arma3.com/dlc/zeus), are used as our framework to create a military scenario for generating data to answer the quantitative research questions.

### 5.4 Experimental Procedures:
#### 5.4.1 Modeling of the Scenario 
Before the beginning of each simulation run, the scenario is modeled according to the independent variables.

#### 5.4.1.1 Scenario 1 "Single-Drone Control" - SpecOps Joint Terminal Attack Controller (JTAC) assigning targets with 1 [UCAV](http://armedassault.wikia.com/wiki/UCAV_Sentinel) and 2 Targets (1 [Anti-Aircraft (AA)-Tank](http://armedassault.wikia.com/wiki/ZSU-39_Tigris), 1 [Armored Personnel Carrier (APC)](http://armedassault.wikia.com/wiki/BTR-K_Kamysh)).
In this scenario the SpecOps JTAC has to coordinate the destruction of the two enemy vehicles with one available UCAV which is armed with three Air to Ground Missiles, before the SpecOPs JTAC and his group can be extracted by a helicopter. 

[The ArmA 3 mission file of Scenario 1 "Single-Drone Control" can be downloaded here](https://github.com/jedioutcast55/project_template/tree/master/Experimental%20Study%20Results/SpecOps%2520JTAC%2520assigning%2520targets%253a1xUCAV%2C2xTargets(1AA%2C1APC).Altis). Copy and paste the scenario folder to the ArmA 3 user mission folder (C:\Users\YOURNAME\Documents\Arma 3\missions) to be able to load the scenario.

#### 5.4.1.2 Scenario 2 "Multi-Drone Control" - SpecOps JTAC assigning targets with 4 [UCAVs](http://armedassault.wikia.com/wiki/UCAV_Sentinel) and 6 Targets (3 [AA-Tanks](http://armedassault.wikia.com/wiki/ZSU-39_Tigris), 1 [APC](http://armedassault.wikia.com/wiki/BTR-K_Kamysh), 2 [Main Battle Tanks (MBTs)](http://armedassault.wikia.com/wiki/T-140K_Angara)).
In this scenario the SpecOps JTAC has to coordinate the destruction of the six enemy vehicles with four available UCAVs which are armed with three Air to Ground Missiles each, before the SpecOPs JTAC and his group can be extracted by a helicopter. 

[The ArmA 3 mission file of Scenario 2 "Multi-Drone Control" can be downloaded here](https://github.com/jedioutcast55/project_template/tree/master/Experimental%20Study%20Results/SpecOps%2520JTAC%2520assigning%2520targets%253a4xUCAV%2C6xTargets(3AA%2C1APC%2C2Tanks).Altis). Copy and paste the scenario folder to the ArmA 3 user mission folder C:\Users\YOURNAME\Documents\Arma 3\missions to be able to load the scenario.

#### 5.4.2. Conducting the simulation experiment 
Running the Simulation in ArmA 3 with a specific scenario. At the end of each Simulation run, the values of the response variables are saved in a excel file.

#### 5.4.2.1 Scenario 1 "Single-Drone Control" - SpecOps JTAC assigning targets with 1 [UCAV](http://armedassault.wikia.com/wiki/UCAV_Sentinel) and 2 Targets (1 [AA-Tank](http://armedassault.wikia.com/wiki/ZSU-39_Tigris), 1 [APC](http://armedassault.wikia.com/wiki/BTR-K_Kamysh)).
* Experiment A: semi-autonomous operation (30 runs): 
The human user remotely controls the weapon use of the single-drone, the flying of the single-drone is carried out autonomously according to the specifications of the human user. The human user decides on the use of weapons and executes it. The single-drone can only carry out its mission through the input of the human user. In this experiment, the human is "in-the-loop."

[![semi-autonomous operation](https://github.com/jedioutcast55/project_template/blob/master/Images/ArmA%203%20Ingame%20Screenshot%20semi-autonomous.JPG)](https://youtu.be/6KmAmXP7uBw)
			
* Experiment B: supervised autonomous operation (30 runs):
The human user assigns the drone a specific target (e.g., destroy the enemy tank on coordinate x, y), which is then engaged autonomously by the single-drone. The use of the single-drone is terminated when the specifically assigned target is destroyed, or the human user decides to cancel the operation. Although the human user decides to use the weapon system as in example 1, however, the execution is done autonomously. The human user assumes the role of a supervisor. In this experiment, the human is "on-the-loop".

[![supervised-autonomous operation](https://github.com/jedioutcast55/project_template/blob/master/Images/ArmA%203%20Ingame%20Screenshot%20supervised-autonomous.JPG)](https://youtu.be/I5x88eliCMw)

[The results of Experiment A and B of Scenario 1 "Single-Drone Control" can be downloaded here.](https://github.com/jedioutcast55/project_template/blob/master/Experimental%20Study%20Results/Experimentation%20Results_1%20UCAV%2C2%20Targets(1AA%2C1APC).xlsx)

#### 5.4.2.2 Scenario 2 "Multi-Drone Control" - SpecOps JTAC assigning targets with 4 [UCAVs](http://armedassault.wikia.com/wiki/UCAV_Sentinel) and 6 Targets (3 [AA-Tanks](http://armedassault.wikia.com/wiki/ZSU-39_Tigris), 1 [APC](http://armedassault.wikia.com/wiki/BTR-K_Kamysh), 2 [MBTs](http://armedassault.wikia.com/wiki/T-140K_Angara)).

* Expriment A: semi-autonomous operation (30 runs): 
The human user remotely controls the weapon use of multiple-drones sequentially, the flying of the drones is carried out autonomously according to the specifications of the human user. The human user decides on the use of weapons and executes it. The drones can only carry out their mission through the input of the human user. In this experiment, the human is "in-the-loop."

Video link tbd
			
* Experiment B: supervised autonomous operation (30 runs):
The human user assigns multiple-drones specific targets (e.g., destroy the enemy tank on coordinate x, y), which are then engaged autonomously by the drone-swarm. The use of the drone-swarm is terminated when the specifically assigned targets are destroyed, or the human user decides to cancel the operation. Although the human user decides to use the weapon system as in example 1, however, the execution is done autonomously. The human user assumes the role of a supervisor. In this experiment, the human is "on-the-loop".

Video link tbd

[The results of Experiment A and B of Scenario 2 "Multi-Drone Control" can be downloaded here.](https://github.com/jedioutcast55/project_template/blob/master/Experimental%20Study%20Results/Experimentation%20Results_4%20UCAV%2C6%20Targets(3AA%2C1APC%2C2Tanks).xlsx)

#### 5.4.3 Analyzing the Data.
After generating the Data during the simulation experiments A and B of Scenarios 1 and 2, a statistical hypothesis test using the software "R" was conducted. 

#### 5.4.3.1 Scenario 1 "Single-Drone Control" - SpecOps JTAC assigning targets with 1 [UCAV](http://armedassault.wikia.com/wiki/UCAV_Sentinel) and 2 Targets (1 [AA-Tank](http://armedassault.wikia.com/wiki/ZSU-39_Tigris), 1 [APC](http://armedassault.wikia.com/wiki/BTR-K_Kamysh)).
T-tests with alpha = 0.05 were used to compare the results of experiment A: **semi-autonomous Operation** and Experiment B: **supervised autonomous Operation.**

* Comparing Amount of destroyed targets: 				**no significant difference**
* Comparing Amount of autonomous Systems at the end of the mission:     **no significant difference**
* Comparing elapsed Time since command received: 			**no significant difference**
* Comparing Amount of Used Ammunition: 					**no significant difference**
* Comparing Only hostile targets engaged: 				**no significant difference**
* Comparing Operator was able to supervise all used autonomous systems: **no significant difference**
* Comparing Operator perception of cognitive workload: 			**significant difference**

[The R-Script to analyse the results of experiment A and B of Scenario 1 "Single-Drone Control" can be downloaded here](https://github.com/jedioutcast55/project_template/blob/master/Experimental%20Study%20Results/Analysis%20Results_1%20UCAV%2C2%20Targets(1AA%2C1APC).R)

#### 5.4.3.2 Scenario 2 "Multi-Drone Control" - SpecOps JTAC assigning targets with 4 [UCAVs](http://armedassault.wikia.com/wiki/UCAV_Sentinel) and 6 Targets (3 [AA-Tanks](http://armedassault.wikia.com/wiki/ZSU-39_Tigris), 1 [APC](http://armedassault.wikia.com/wiki/BTR-K_Kamysh), 2 [MBTs](http://armedassault.wikia.com/wiki/T-140K_Angara)).

* Comparing Amount of destroyed targets: 				 **no significant difference**
* Comparing Amount of autonomous Systems at the end of the mission: 	 **no significant difference**
* Comparing elapsed Time since command received: 			 **significant difference**
* Comparing Amount of Used Ammunition: 					 **no significant difference**
* Comparing Only hostile targets engaged: 				 **no significant difference**
* Comparing Operator was able to supervise all used autonomous systems:  **no significant difference**
* Comparing Operator perception of cognitive workload: 			 **significant difference**

[The R-Script to analyse the Results of Experiment A and B of Scenario 2 "Multi-Drone Control" can be downloaded here](https://github.com/jedioutcast55/project_template/blob/master/Experimental%20Study%20Results/Analysis%20Results_4%20UCAV%2C6%20Targets(3AA%2C1APC%2C2Tanks).R)

## 6. Experimental Study Results

### 6.1 Hypothesis 1:
Unmanned Systems can be operated autonomously with the same reliability as a Human-operated one in a virtual military scenario when there is no significant difference between the outcomes of experiment A and B for each Scenario. 

* Ho: There is no sufficient evidence for a difference in reliability.
* Ha: There is a sufficient evidence for a difference in reliability.

In the first scenario, we are comparing current drone operations versus autonomous drones with human supervision.  The formulated hypothesis (Hypothesis 1) an Unmanned Systems can be operated autonomously with the same reliability as Human-operated once in a virtual scenario.  The null hypothesis Ho: There is no sufficient evidence for a difference in reliability.  With our alternate hypothesis Ha: There is a sufficient evidence for a difference in reliability.  Experiment A represents today’s operations.  Experiment B represents human supervision of an autonomous drone.  Using a correlated (or paired) T-test to compare the dependent variables (section 5.2.2) from experiment A and experiment B.  

Experiment A uses a two-man crew to operate the drone.  A conversation with one of our classmates knowledgeable in drone operations informed us that most of the flying is performed autonomously.  The two crew members concentrate on targeting and the release of weapons.  In experiment A, one operator is replaced with the ArmA 3 platform’s simulated agent.  The simulated agent flies the drone and the human operator performs targeting and release of weapons.  
   
In experiment B we use the human operator in a supervisory capacity of the drone’s operations.  The human supervisor will keep situational awareness and select the drone’s targets.  All other operations are performed by the drone's artificial intelligent (AI) systems.  For detailed explanations of scenario one see section 5.4.2.1.  After 30 runs for each experiment, we have analyzed the data using the T-test.
   
![T-Test Results Scenario One Fig1](https://github.com/jedioutcast55/project_template/blob/master/Images/Scenario_one_TargetDestroyedAndAmountofUCAV.jpg)
Figure 1: Shows Scenario One T-Test results for Left: Amount of destroyed targets and Right: Amount of autonomous Systems at the end of the mission (both variables showing no significant difference)

The T-test results (5.4.3.1) showed there were no major differences between six of the seven dependent variables. For these six variables, we could not reject Ho: There is no sufficient evidence for a difference in reliability. Operator perception of cognitive workload is the variable for which we can reject the null hypothesis. We accept the alternate hypothesis Ha: There is sufficient evidence for a difference in reliability. The data show experiment B having an advantage over experiment A for the variable showing significant differences in reliability. We can infer that the results do not show that drones operating in a human-in-the-loop (experiment A) are more reliable than drones operating in a human-on-the-loop (experiment B).
 
![T-Test Results Scenario One Fig2](https://github.com/jedioutcast55/project_template/blob/master/Images/Scenario_one_ElapseTimeandCognotiveLoad.jpg)
Figure 2: Shows Scenario One T-Test results for Left: elapsed Time since command received (no significant difference) and Right: Operator perception of cognitive workload (significant difference)

### 6.2 Hypothesis 2:
By using autonomous systems, military missions can be conducted with less human personnel.

* Ho: Missions conducted with less human personnel supervising autonomous systems are no different than conducted by human control systems.
* Ha: Missions conducted with less human personnel supervising autonomous systems are different than conducted by human control systems.

In the second scenario, we are comparing the human control operation of a swarm (four) of drones versus a swarm of autonomous drones with human supervision. The formulated hypothesis (Hypothesis 2) is By using autonomous systems, military missions can be conducted with less human personnel. The null hypothesis Ho: Missions conducted with less human personnel supervising autonomous systems are no different than conducted by human control systems.  With our alternate hypothesis Ha: Missions conducted with less human personnel supervising autonomous systems are different than those conducted by human control systems. As in scenario one, experiment A represents a human-in-the-loop. The human operator takes a direct control of the drones targeting and release of weapons. Experiment B represents human supervision (human-on-the-loop) of four autonomous drones. Using a correlated (or paired) T-test to compare the dependent variables (section 5.2.2) from experiment A and experiment B. 

Experiment A uses a one-man crew to operate four drones. In experiment A, the drones are flown by ArmA 3 platform’s simulated agent and the human operator targets and the release of weapons. The human performed the targeting and firing for all four drones. As we do not have a reference for this type of mission, we represented experiment A in a similar fashion as experiment A from scenario one.    
   
In experiment B we use the human operator in a supervisory capacity of drones’ operations. For detailed explanations of scenario two, see section 5.4.2.2 of this document. After 30 runs for each experiment, we have analyzed the data using the T-test.
     
![T-Test Results Scenario Two Fig3](https://github.com/jedioutcast55/project_template/blob/master/Images/Scenario_Two_TargetDestroyedandAmountofUCAV.jpg)
Figure 3: Shows Scenario Two T-Test results for Left: Amount of destroyed targets and Right: Amount of autonomous Systems at the end of the mission (both variables showing no significant difference)

The T-test results (5.4.3.2) show were no major differences between five of the seven of the dependent variables. For these five variables, we could not reject Ho: Missions conducted with less human personnel supervising autonomous systems are no different than conducted by human control systems. The two variables for which can reject the hypothesis are Elapsed Time since command received and Operator perception of cognitive workload. We accept the alternate hypothesis Ha: Missions conducted with less human personnel supervising autonomous systems are different than those conducted by human control systems. The data show experiment B having an advantage over experiment A for the variables showing a significant difference. These results do not show that drones operating in a human-in-the-loop (experiment A) are significant different from drones operating in a human-on-the-loop (experiment B). We can infer from the results that there is no evidence semi-autonomous system using less human personnel controlling the drones are more efficient than the supervised autonomous system. The two variables showing significant difference seem to favor experiment B.
   
![T-Test Results Scenario Two Fig4](https://github.com/jedioutcast55/project_template/blob/master/Images/Scenario_Two_ElapseTimeandCognotiveLoad.jpg)
Figure 4: Shows Scenario Two T-Test results for Left: elapsed Time since command received and Right: Operator perception of cognitive workload (both variables with significant difference)

## 7. Future Research
If we had 1-2 more semesters we would do next and hope to accomplish and study Hypothesis 3 ...
...

## 8. Conclusion
Our team interest in studying Human-Assisted Weapon Systems and the validity of human-autonomy teaming in the not so distant future.  These two interesting subjects were the focal point of our project.  We also intended to bring forth the military tactical shooter video game ArmA 3 as a modeling and simulation platform to demonstrate some of our concept and experimentations of the project’s hypothesis.  The situation brought us to the conclusion that our research methodology needed to be a mixed method approach.

  In the qualitative approach, we found literature evidence on the benefit of using human-supervised autonomous systems in a military environment.  The military was able to increase its capabilities with the introduction of UVs and robotic systems (Squire & Parasuraman, 2010) (de Visser & Parasuraman, 2011) (Chen & Barnes 2014).  These systems increase the force lethality and reduce the soldiers’ exposure to combat (Chen & Barnes 2014).  With other the benefits such production reduction and increase in safety (Squire & Parasuraman, 2010) (Endsley, 2017).
  
   We have also look at what is the status of human-autonomy teaming research.  The subjects of current research are on small robots, intelligent systems, human-intelligent agent teaming, etc. (Chen, 2018).  We see a lot of research performed on the cognitive load of the human agent within the human-autonomy construct (Demir, McNeese, and Cooke, 2018).
   
   Another major topic of discussion was the ethical and legal implications of the operations of these autonomous systems in the military environment.  On these subjects we found that systems must be created in a manner that they always are subordinates to humans, they were only be allowed to act autonomously only in specific conditions under human supervision with the ability to cancel the autonomous task at any time (Chen & Barnes 2014).  The inference in here is that the human has the ultimate responsibility for the legal and ethical implications of the autonomous system’s actions.
   
  Our quantitative approach explores the viability of ArmA 3 as a modeling and simulation platform.  Scenario one was created for a human-autonomy teaming comparison between supervised operations to current drones’ operations.  The results of a T-Test showed there was no significant difference showed between six of the seven dependent variables (5.2.2) of collected data. Therefore, we could not drop our Hypothesis 1: Unmanned Systems can be operated autonomously with the same reliability as human-operated once in a virtual military scenario.
  
   The second scenario was created to simulate human-autonomy teaming operation with less human personnel.  The first scenario showed one human handling one drone.  The second scenario shows one human handling a swarm of four drones. On the second scenario when comparing both experiments where one human the controls the drone’s functions and the second the human supervises the drones; the results of the T-Test showed no significant difference between five of the seven dependent variables (5.2.2).  Therefore, we could not drop our Hypothesis 2: By using autonomous systems, military missions can be conducted with less human personnel.
   
   In both scenarios, the variables that were found to have a significant difference were in favor of the human supervise experiments and they did not allow for the elimination of either of the hypothesis.
   
   In all the results supplied a positive indication that ArmA 3 can be used as a modeling and simulation platform to conduct preliminary testing of our hypotheses.  ArmA 3 allows for the creation of complex scenarios which supplied useful data.  The scenarios tested the skills of both the human in the experiment as well as the simulated agent within the system.  These results were positive enough to give us the confidence to continue researching the topics presented in this paper.


## 9. Plan of attack for the rest of the semester
### Final Presentation 12/04/2018
* Research Methodology finalized NLT 11/29/2018
* Qualitative Research finalized  NLT 11/29/2018
* Quantitative Research finalized NLT 11/24/2018
* GitHub documentary finalized 	  NLT 12/05/2018  

## References 
* [Armed Assault Wiki (2018)](http://armedassault.wikia.com/wiki/Armed_Assault_Wiki)
* [Chen, J. Y., & Barnes, M. J. (2014). Human–agent teaming for multirobot control: A review of human factors issues. IEEE Transactions on Human-Machine Systems, 44(1), 13-29.](https://ieeexplore.ieee.org/document/6697830/)
* [Chen, J. Y. (2018). Human-autonomy teaming in military settings. Theoretical Issues in Ergonomics Science, 19(3), 255-258.](https://www.tandfonline.com/doi/abs/10.1080/1463922X.2017.1397229)
* [Chen, J. Y., Lakhmani, S. G., Stowers, K., Selkowitz, A. R., Wright, J. L., & Barnes, M. (2018). Situation awareness-based agent transparency and human-autonomy teaming effectiveness. Theoretical issues in ergonomics science, 19(3), 259-282.](https://www.tandfonline.com/doi/abs/10.1080/1463922X.2017.1315750)
* [Chesebrough, D., & Dooley, M. (2018, September 13). Defense Department Struggles to Define Autonomy. Retrieved from http://www.nationaldefensemagazine.org/articles/2018/9/13/defense-department-struggles-to-define-autonomy](http://www.nationaldefensemagazine.org/articles/2018/9/13/defense-department-struggles-to-define-autonomy)
* [Creswell, J. W., & Creswell, J. D. (2017). Research design: Qualitative, quantitative, and mixed methods approaches. Sage publications.](https://us.sagepub.com/en-us/nam/research-design/book255675)
* [de Boisboissel, G. (2017). Is it sensible to grant autonomous decision-making to military robots of the future?. In Military Technologies (ICMT), 2017 International Conference on (pp. 738-742). IEEE.](https://ieeexplore.ieee.org/document/7988854/)
* [Defense Science Board. 2016. Defense Science Board Summer Study on Autonomy. Washington, DC:Under Secretary of Defense.](https://www.hsdl.org/?view&did=794641)
* [Demir M., McNeese N.J., Cooke N.J. (2018) Team Synchrony in Human-Autonomy Teaming. In: Chen J. (eds) Advances in Human Factors in Robots and Unmanned Systems. AHFE 2017. Advances in Intelligent Systems and Computing, vol 595. Springer, Cham](http://journals.sagepub.com/doi/10.1177/0018720816681350)
* [Dyndal, G., & Redse-Johansen, S. (2017). Autonomous military drones: no longer science fiction. NATO Review Magazine.](https://www.nato.int/docu/review/2017/also-in-2017/autonomous-military-drones-no-longer-science-fiction/en/index.htm)
* [Endsley, M. R. (2017). From here to autonomy: lessons learned from human–automation research. Human factors, 59(1), 5-27.](https://link.springer.com/chapter/10.1007%2F978-3-319-60384-1_29)
* [Hawking, S. (2014). Transcendence looks at the implications of artificial intelligence—but are we taking AI seriously enough? The Independent.](https://www.independent.co.uk/news/science/stephen-hawking-transcendence-looks-at-the-implications-of-artificial-intelligence-but-are-we-taking-9313474.html)
* [Millington, I., & Funge, J. (2009). Artificial intelligence for games. CRC Press.](https://www.crcpress.com/Artificial-Intelligence-for-Games/Millington-Millington-Funge/p/book/9780123747310)
* [Reuters (2018, September 19). Ageing Japan: Military recruiters struggle as applicant pool dries up. Retrieved from https://in.reuters.com/article/japan-ageing-military-recruits/ageing-japan-military-recruiters-struggle-as-applicant-pool-dries-up-idINKCN1LZ146](https://in.reuters.com/article/japan-ageing-military-recruits/ageing-japan-military-recruiters-struggle-as-applicant-pool-dries-up-idINKCN1LZ146)
* [Sadraey, M. H. (2018). Manned-unmanned aircraft teaming. In 2018 IEEE Aerospace Conference (pp. 1-12). IEEE.](https://ieeexplore.ieee.org/document/8396747/)
* [Scharre, P. (2018). Army of None: Autonomous Weapons and the Future of War. WW Norton & Company.](https://books.google.com/books?hl=de&lr=&id=sjMsDwAAQBAJ&oi=fnd&pg=PT7&dq=Army+of+None&ots=T8z0gGG0IW&sig=nIZIAWaqnNoPhMiFCTqo5gdNHeY#v=onepage&q=Army%20of%20None&f=false)
* [Squire, P. N., & Parasuraman, R. (2010). Effects of automation and task load on task switching during human supervision of multiple semi-autonomous robots in a dynamic environment. Ergonomics, 53(8), 951-961.](https://www.tandfonline.com/doi/full/10.1080/00140139.2010.489969)
* [Vinge, V. (1993). The coming technological singularity: How to survive in the post-human era.](https://edoras.sdsu.edu/~vinge/misc/singularity.html)
* [Warren, A., & Hillas, A. (2017). Lethal Autonomous Weapons Systems: Adapting to the Future Unmanned Warfare and Unaccountable Robots. Yale J. Int'l Aff., 12, 71.](https://heinonline.org/HOL/LandingPage?handle=hein.journals/yaljoina12&div=12&id=&page=)
* [Yilmaz, L., Ören, T., & Aghaee, N. G. (2006). Intelligent agents, simulation, and gaming. Simulation & Gaming, 37(3), 339-349.](http://journals.sagepub.com/doi/abs/10.1177/1046878106289089)
* [Youtube (2013, July 10). X-47B Completes First Carrier-based Arrested Landing. Retrieved from https://www.youtube.com/watch?v=Rc2k6G8LuqY](https://www.youtube.com/watch?v=Rc2k6G8LuqY)
* [Youtube (2016, June 18). ARMA 3 - Advanced AI Command Tactics w/ ALIVE Combat Support & High Command (Full Mission). Retrieved from https://www.youtube.com/watch?v=QphmHgvYlJw&t=1290s](https://www.youtube.com/watch?v=QphmHgvYlJw&t=1290s)
